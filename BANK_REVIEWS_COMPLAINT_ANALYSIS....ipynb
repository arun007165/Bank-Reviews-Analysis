{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center>\n",
    "<h1> BANK REVIEWS COMPLAINT ANALYSIS\n",
    "</center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import required packages\n",
    "#basics\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "\n",
    "#misc\n",
    "import gc\n",
    "import time\n",
    "import warnings\n",
    "\n",
    "#stats\n",
    "#from scipy.misc import imread\n",
    "from scipy import sparse\n",
    "import scipy.stats as ss\n",
    "\n",
    "#viz\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec \n",
    "import seaborn as sns\n",
    "from wordcloud import WordCloud ,STOPWORDS\n",
    "from PIL import Image\n",
    "#import matplotlib_venn as venn\n",
    "\n",
    "#nlp\n",
    "import string\n",
    "import re    #for regex\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "#import spacy\n",
    "from nltk import pos_tag\n",
    "from nltk.stem.wordnet import WordNetLemmatizer \n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "# Tweet tokenizer does not split at apostophes which is what we want\n",
    "from nltk.tokenize import TweetTokenizer   \n",
    "\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "\n",
    "#FeatureEngineering\n",
    "#!pip install lightgbm\n",
    "#from lightgbm import LGBMClassifier\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer, HashingVectorizer, TfidfTransformer\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.base import BaseEstimator, ClassifierMixin\n",
    "from sklearn.utils.validation import check_X_y, check_is_fitted\n",
    "from sklearn import model_selection, preprocessing, linear_model, naive_bayes, metrics, svm, decomposition, ensemble\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import  textblob\n",
    "#import xgboost\n",
    "#from keras.preprocessing import text, sequence\n",
    "#from keras import layers, models, optimizers\n",
    "\n",
    "from textblob import TextBlob\n",
    "from nltk.stem import PorterStemmer\n",
    "import nltk\n",
    "#nltk.download('wordnet')\n",
    "from textblob import Word\n",
    "\n",
    "#settings\n",
    "start_time=time.time()\n",
    "color = sns.color_palette()\n",
    "sns.set_style(\"dark\")\n",
    "eng_stopwords = set(stopwords.words(\"english\"))\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "lem = WordNetLemmatizer()\n",
    "tokenizer=TweetTokenizer()\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "bankreviews = pd.read_excel(\"BankReviews.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Stars</th>\n",
       "      <th>Reviews</th>\n",
       "      <th>BankName</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2017-04-10</td>\n",
       "      <td>5</td>\n",
       "      <td>Great job, Wyndham Capital! Each person was pr...</td>\n",
       "      <td>Wyndham Capital Mortgage</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2017-02-10</td>\n",
       "      <td>5</td>\n",
       "      <td>Matthew Richardson is professional and helpful...</td>\n",
       "      <td>Wyndham Capital Mortgage</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2017-08-21</td>\n",
       "      <td>5</td>\n",
       "      <td>We had a past experience with Wyndham Mortgage...</td>\n",
       "      <td>Wyndham Capital Mortgage</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2017-12-17</td>\n",
       "      <td>5</td>\n",
       "      <td>We have been dealing with Brad Thomka from the...</td>\n",
       "      <td>Wyndham Capital Mortgage</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2016-05-27</td>\n",
       "      <td>5</td>\n",
       "      <td>I can't express how grateful I am for the supp...</td>\n",
       "      <td>Wyndham Capital Mortgage</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Date  Stars                                            Reviews  \\\n",
       "0 2017-04-10      5  Great job, Wyndham Capital! Each person was pr...   \n",
       "1 2017-02-10      5  Matthew Richardson is professional and helpful...   \n",
       "2 2017-08-21      5  We had a past experience with Wyndham Mortgage...   \n",
       "3 2017-12-17      5  We have been dealing with Brad Thomka from the...   \n",
       "4 2016-05-27      5  I can't express how grateful I am for the supp...   \n",
       "\n",
       "                   BankName  \n",
       "0  Wyndham Capital Mortgage  \n",
       "1  Wyndham Capital Mortgage  \n",
       "2  Wyndham Capital Mortgage  \n",
       "3  Wyndham Capital Mortgage  \n",
       "4  Wyndham Capital Mortgage  "
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bankreviews.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "bankreviews=bankreviews[['Stars', 'Reviews', 'BankName']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Stars</th>\n",
       "      <th>Reviews</th>\n",
       "      <th>BankName</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>Great job, Wyndham Capital! Each person was pr...</td>\n",
       "      <td>Wyndham Capital Mortgage</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>Matthew Richardson is professional and helpful...</td>\n",
       "      <td>Wyndham Capital Mortgage</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>We had a past experience with Wyndham Mortgage...</td>\n",
       "      <td>Wyndham Capital Mortgage</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>We have been dealing with Brad Thomka from the...</td>\n",
       "      <td>Wyndham Capital Mortgage</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>I can't express how grateful I am for the supp...</td>\n",
       "      <td>Wyndham Capital Mortgage</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Stars                                            Reviews  \\\n",
       "0      5  Great job, Wyndham Capital! Each person was pr...   \n",
       "1      5  Matthew Richardson is professional and helpful...   \n",
       "2      5  We had a past experience with Wyndham Mortgage...   \n",
       "3      5  We have been dealing with Brad Thomka from the...   \n",
       "4      5  I can't express how grateful I am for the supp...   \n",
       "\n",
       "                   BankName  \n",
       "0  Wyndham Capital Mortgage  \n",
       "1  Wyndham Capital Mortgage  \n",
       "2  Wyndham Capital Mortgage  \n",
       "3  Wyndham Capital Mortgage  \n",
       "4  Wyndham Capital Mortgage  "
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bankreviews.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basic Exploratory Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = bankreviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Reviews'] = df['Reviews'].astype(str)\n",
    "df['count_sent']=df[\"Reviews\"].apply(lambda x: len(re.findall(\"\\n\",str(x)))+1)\n",
    "\n",
    "#Word count in each comment:\n",
    "df['count_word']=df[\"Reviews\"].apply(lambda x: len(str(x).split()))\n",
    "\n",
    "#Unique word count\n",
    "df['count_unique_word']=df[\"Reviews\"].apply(lambda x: len(set(str(x).split())))\n",
    "\n",
    "#Letter count\n",
    "df['count_letters']=df[\"Reviews\"].apply(lambda x: len(str(x)))\n",
    "\n",
    "#Word density\n",
    "\n",
    "df['word_density'] = df['count_letters'] / (df['count_word']+1)\n",
    "\n",
    "#punctuation count\n",
    "df[\"count_punctuations\"] =df[\"Reviews\"].apply(lambda x: len([c for c in str(x) if c in string.punctuation]))\n",
    "\n",
    "#upper case words count\n",
    "df[\"count_words_upper\"] = df[\"Reviews\"].apply(lambda x: len([w for w in str(x).split() if w.isupper()]))\n",
    "\n",
    "#upper case words count\n",
    "df[\"count_words_lower\"] = df[\"Reviews\"].apply(lambda x: len([w for w in str(x).split() if w.islower()]))\n",
    "\n",
    "#title case words count\n",
    "df[\"count_words_title\"] = df[\"Reviews\"].apply(lambda x: len([w for w in str(x).split() if w.istitle()]))\n",
    "\n",
    "#Number of stopwords\n",
    "df[\"count_stopwords\"] = df[\"Reviews\"].apply(lambda x: len([w for w in str(x).lower().split() if w in eng_stopwords]))\n",
    "\n",
    "#Average length of the words\n",
    "df[\"mean_word_len\"] = df[\"Reviews\"].apply(lambda x: np.mean([len(w) for w in str(x).split()]))\n",
    "\n",
    "#Number of numeric\n",
    "df['numeric'] = df['Reviews'].apply(lambda x :len([x for x in x.split() if x.isdigit()]))\n",
    "\n",
    "#Number of alphanumeric\n",
    "df['alphanumeric'] = df['Reviews'].apply(lambda x :len([x for x in x.split() if x.isalnum()]))\n",
    "\n",
    "#Number of alphabetics\n",
    "df['alphabetetics'] = df['Reviews'].apply(lambda x :len([x for x in x.split() if x.isalpha()]))\n",
    "\n",
    "#Number of alphabetics\n",
    "df['Spaces'] = df['Reviews'].apply(lambda x :len([x for x in x.split() if x.isspace()]))\n",
    "\n",
    "#Number of Words ends with\n",
    "df['words_ends_with_et'] = df['Reviews'].apply(lambda x :len([x for x in x.lower().split() if x.endswith('et')]))\n",
    "\n",
    "#Number of Words ends with\n",
    "df['words_start_with_no'] = df['Reviews'].apply(lambda x :len([x for x in x.lower().split() if x.startswith('no')]))\n",
    "\n",
    "# Count the occurences of all words\n",
    "df['wordcounts'] = df['Reviews'].apply(lambda x :dict([ [t, x.split().count(t)] for t in set(x.split()) ]))\n",
    "\n",
    "pos_family = {\n",
    "    'noun' : ['NN','NNS','NNP','NNPS'],\n",
    "    'pron' : ['PRP','PRP$','WP','WP$'],\n",
    "    'verb' : ['VB','VBD','VBG','VBN','VBP','VBZ'],\n",
    "    'adj' :  ['JJ','JJR','JJS'],\n",
    "    'adv' : ['RB','RBR','RBS','WRB']\n",
    "}\n",
    "\n",
    "# function to check and get the part of speech tag count of a words in a given sentence\n",
    "def check_pos_tag(x, flag):\n",
    "    cnt = 0\n",
    "    try:\n",
    "        wiki = textblob.TextBlob(x)\n",
    "        for tup in wiki.tags:\n",
    "            ppo = list(tup)[1]\n",
    "            if ppo in pos_family[flag]:\n",
    "                cnt += 1\n",
    "    except:\n",
    "        pass\n",
    "    return cnt\n",
    "\n",
    "df['noun_count'] = df['Reviews'].apply(lambda x: check_pos_tag(x, 'noun'))\n",
    "df['verb_count'] = df['Reviews'].apply(lambda x: check_pos_tag(x, 'verb'))\n",
    "df['adj_count']  = df['Reviews'].apply(lambda x: check_pos_tag(x, 'adj'))\n",
    "df['adv_count']  = df['Reviews'].apply(lambda x: check_pos_tag(x, 'adv'))\n",
    "df['pron_count'] = df['Reviews'].apply(lambda x: check_pos_tag(x, 'pron')) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculating Sentiment analysis using Textblob module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "bankreviews['sentiment'] = bankreviews[\"Reviews\"].apply(lambda x: TextBlob(x).sentiment.polarity )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Stars</th>\n",
       "      <th>Reviews</th>\n",
       "      <th>BankName</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>Great job, Wyndham Capital! Each person was pr...</td>\n",
       "      <td>Wyndham Capital Mortgage</td>\n",
       "      <td>0.533333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>Matthew Richardson is professional and helpful...</td>\n",
       "      <td>Wyndham Capital Mortgage</td>\n",
       "      <td>0.453333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>We had a past experience with Wyndham Mortgage...</td>\n",
       "      <td>Wyndham Capital Mortgage</td>\n",
       "      <td>-0.033231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>We have been dealing with Brad Thomka from the...</td>\n",
       "      <td>Wyndham Capital Mortgage</td>\n",
       "      <td>0.093740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>I can't express how grateful I am for the supp...</td>\n",
       "      <td>Wyndham Capital Mortgage</td>\n",
       "      <td>0.125000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Stars                                            Reviews  \\\n",
       "0      5  Great job, Wyndham Capital! Each person was pr...   \n",
       "1      5  Matthew Richardson is professional and helpful...   \n",
       "2      5  We had a past experience with Wyndham Mortgage...   \n",
       "3      5  We have been dealing with Brad Thomka from the...   \n",
       "4      5  I can't express how grateful I am for the supp...   \n",
       "\n",
       "                   BankName  sentiment  \n",
       "0  Wyndham Capital Mortgage   0.533333  \n",
       "1  Wyndham Capital Mortgage   0.453333  \n",
       "2  Wyndham Capital Mortgage  -0.033231  \n",
       "3  Wyndham Capital Mortgage   0.093740  \n",
       "4  Wyndham Capital Mortgage   0.125000  "
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bankreviews.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5    410\n",
       "1     95\n",
       "Name: Stars, dtype: int64"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bankreviews.Stars.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split the data into train & Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(378,)\n",
      "(127,)\n",
      "(378,)\n",
      "(127,)\n"
     ]
    }
   ],
   "source": [
    "# create a new DataFrame that only contains the 5-star and 1-star reviews\n",
    "#yelp_best_worst = yelp[(yelp.stars==5) | (yelp.stars==1)]\n",
    "\n",
    "# define X and y\n",
    "X = bankreviews.Reviews\n",
    "y = bankreviews.Stars\n",
    "\n",
    "# split the new DataFrame into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=1)\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(505, 4)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bankreviews.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Stars</th>\n",
       "      <th>Reviews</th>\n",
       "      <th>BankName</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>Great job, Wyndham Capital! Each person was pr...</td>\n",
       "      <td>Wyndham Capital Mortgage</td>\n",
       "      <td>0.533333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>Matthew Richardson is professional and helpful...</td>\n",
       "      <td>Wyndham Capital Mortgage</td>\n",
       "      <td>0.453333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>We had a past experience with Wyndham Mortgage...</td>\n",
       "      <td>Wyndham Capital Mortgage</td>\n",
       "      <td>-0.033231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>We have been dealing with Brad Thomka from the...</td>\n",
       "      <td>Wyndham Capital Mortgage</td>\n",
       "      <td>0.093740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>I can't express how grateful I am for the supp...</td>\n",
       "      <td>Wyndham Capital Mortgage</td>\n",
       "      <td>0.125000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Stars                                            Reviews  \\\n",
       "0      5  Great job, Wyndham Capital! Each person was pr...   \n",
       "1      5  Matthew Richardson is professional and helpful...   \n",
       "2      5  We had a past experience with Wyndham Mortgage...   \n",
       "3      5  We have been dealing with Brad Thomka from the...   \n",
       "4      5  I can't express how grateful I am for the supp...   \n",
       "\n",
       "                   BankName  sentiment  \n",
       "0  Wyndham Capital Mortgage   0.533333  \n",
       "1  Wyndham Capital Mortgage   0.453333  \n",
       "2  Wyndham Capital Mortgage  -0.033231  \n",
       "3  Wyndham Capital Mortgage   0.093740  \n",
       "4  Wyndham Capital Mortgage   0.125000  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bankreviews.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating user defined functions for clean the text and pre-process the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Abbrevations and Words correction\n",
    "def clean_text(Reviews):\n",
    "    Reviews = Reviews.lower()\n",
    "    Reviews = Reviews.strip()\n",
    "    Reviews = re.sub(r' +', ' ', Reviews)\n",
    "    Reviews = re.sub(r\"[-()\\\"#/@;:{}`+=~|.!?,'0-9]\", \"\", Reviews)\n",
    "    return(Reviews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['i',\n",
       " 'me',\n",
       " 'my',\n",
       " 'myself',\n",
       " 'we',\n",
       " 'our',\n",
       " 'ours',\n",
       " 'ourselves',\n",
       " 'you',\n",
       " \"you're\",\n",
       " \"you've\",\n",
       " \"you'll\",\n",
       " \"you'd\",\n",
       " 'your',\n",
       " 'yours',\n",
       " 'yourself',\n",
       " 'yourselves',\n",
       " 'he',\n",
       " 'him',\n",
       " 'his',\n",
       " 'himself',\n",
       " 'she',\n",
       " \"she's\",\n",
       " 'her',\n",
       " 'hers',\n",
       " 'herself',\n",
       " 'it',\n",
       " \"it's\",\n",
       " 'its',\n",
       " 'itself',\n",
       " 'they',\n",
       " 'them',\n",
       " 'their',\n",
       " 'theirs',\n",
       " 'themselves',\n",
       " 'what',\n",
       " 'which',\n",
       " 'who',\n",
       " 'whom',\n",
       " 'this',\n",
       " 'that',\n",
       " \"that'll\",\n",
       " 'these',\n",
       " 'those',\n",
       " 'am',\n",
       " 'is',\n",
       " 'are',\n",
       " 'was',\n",
       " 'were',\n",
       " 'be',\n",
       " 'been',\n",
       " 'being',\n",
       " 'have',\n",
       " 'has',\n",
       " 'had',\n",
       " 'having',\n",
       " 'do',\n",
       " 'does',\n",
       " 'did',\n",
       " 'doing',\n",
       " 'a',\n",
       " 'an',\n",
       " 'the',\n",
       " 'and',\n",
       " 'but',\n",
       " 'if',\n",
       " 'or',\n",
       " 'because',\n",
       " 'as',\n",
       " 'until',\n",
       " 'while',\n",
       " 'of',\n",
       " 'at',\n",
       " 'by',\n",
       " 'for',\n",
       " 'with',\n",
       " 'about',\n",
       " 'against',\n",
       " 'between',\n",
       " 'into',\n",
       " 'through',\n",
       " 'during',\n",
       " 'before',\n",
       " 'after',\n",
       " 'above',\n",
       " 'below',\n",
       " 'to',\n",
       " 'from',\n",
       " 'up',\n",
       " 'down',\n",
       " 'in',\n",
       " 'out',\n",
       " 'on',\n",
       " 'off',\n",
       " 'over',\n",
       " 'under',\n",
       " 'again',\n",
       " 'further',\n",
       " 'then',\n",
       " 'once',\n",
       " 'here',\n",
       " 'there',\n",
       " 'when',\n",
       " 'where',\n",
       " 'why',\n",
       " 'how',\n",
       " 'all',\n",
       " 'any',\n",
       " 'both',\n",
       " 'each',\n",
       " 'few',\n",
       " 'more',\n",
       " 'most',\n",
       " 'other',\n",
       " 'some',\n",
       " 'such',\n",
       " 'no',\n",
       " 'nor',\n",
       " 'not',\n",
       " 'only',\n",
       " 'own',\n",
       " 'same',\n",
       " 'so',\n",
       " 'than',\n",
       " 'too',\n",
       " 'very',\n",
       " 's',\n",
       " 't',\n",
       " 'can',\n",
       " 'will',\n",
       " 'just',\n",
       " 'don',\n",
       " \"don't\",\n",
       " 'should',\n",
       " \"should've\",\n",
       " 'now',\n",
       " 'd',\n",
       " 'll',\n",
       " 'm',\n",
       " 'o',\n",
       " 're',\n",
       " 've',\n",
       " 'y',\n",
       " 'ain',\n",
       " 'aren',\n",
       " \"aren't\",\n",
       " 'couldn',\n",
       " \"couldn't\",\n",
       " 'didn',\n",
       " \"didn't\",\n",
       " 'doesn',\n",
       " \"doesn't\",\n",
       " 'hadn',\n",
       " \"hadn't\",\n",
       " 'hasn',\n",
       " \"hasn't\",\n",
       " 'haven',\n",
       " \"haven't\",\n",
       " 'isn',\n",
       " \"isn't\",\n",
       " 'ma',\n",
       " 'mightn',\n",
       " \"mightn't\",\n",
       " 'mustn',\n",
       " \"mustn't\",\n",
       " 'needn',\n",
       " \"needn't\",\n",
       " 'shan',\n",
       " \"shan't\",\n",
       " 'shouldn',\n",
       " \"shouldn't\",\n",
       " 'wasn',\n",
       " \"wasn't\",\n",
       " 'weren',\n",
       " \"weren't\",\n",
       " 'won',\n",
       " \"won't\",\n",
       " 'wouldn',\n",
       " \"wouldn't\"]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stop = set(nltk.corpus.stopwords.words('english'))\n",
    "\n",
    "nltk.corpus.stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "def pre_process(Reviews):\n",
    "    Reviews = Reviews.apply(lambda x: \" \".join(x for x in x.split() if x not in stop)) #Removing stop words\n",
    "    return(Reviews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.apply(lambda x: clean_text(x))\n",
    "X_test = X_test.apply(lambda x: clean_text(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train=pre_process(X_train)\n",
    "X_test=pre_process(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vectorization (Count, Tfidf, Hashing)\n",
    " - Charter level\n",
    " - Word level\n",
    " - n-grams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train\n",
    "count_vect = CountVectorizer(analyzer='word', token_pattern=r'\\w{1,}', \n",
    "                             ngram_range=(1, 1 ), \n",
    "                             min_df=0.01, \n",
    "                             encoding='latin-1' ,\n",
    "                             max_features=800)\n",
    "xtrain_count = count_vect.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<378x732 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 9755 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xtrain_count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### View the document term metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtm=xtrain_count.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, ..., 0, 1, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0]], dtype=int64)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dtm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['aaron',\n",
       " 'ability',\n",
       " 'able',\n",
       " 'absolutely',\n",
       " 'accept',\n",
       " 'accommodating',\n",
       " 'account',\n",
       " 'accurate',\n",
       " 'achieve',\n",
       " 'across',\n",
       " 'actual',\n",
       " 'actually',\n",
       " 'adam',\n",
       " 'adan',\n",
       " 'additional',\n",
       " 'advice',\n",
       " 'agent',\n",
       " 'agreed',\n",
       " 'alex',\n",
       " 'almost',\n",
       " 'along',\n",
       " 'already',\n",
       " 'also',\n",
       " 'always',\n",
       " 'amazing',\n",
       " 'american',\n",
       " 'amount',\n",
       " 'another',\n",
       " 'answer',\n",
       " 'answered',\n",
       " 'answering',\n",
       " 'answers',\n",
       " 'anthony',\n",
       " 'anyone',\n",
       " 'anything',\n",
       " 'application',\n",
       " 'apply',\n",
       " 'appraisal',\n",
       " 'appraiser',\n",
       " 'appreciate',\n",
       " 'appreciated',\n",
       " 'approved',\n",
       " 'around',\n",
       " 'ask',\n",
       " 'asked',\n",
       " 'asking',\n",
       " 'aspects',\n",
       " 'asset',\n",
       " 'attention',\n",
       " 'attentive',\n",
       " 'attorney',\n",
       " 'available',\n",
       " 'away',\n",
       " 'awesome',\n",
       " 'back',\n",
       " 'bad',\n",
       " 'balance',\n",
       " 'bank',\n",
       " 'banks',\n",
       " 'barrett',\n",
       " 'based',\n",
       " 'basis',\n",
       " 'beat',\n",
       " 'became',\n",
       " 'began',\n",
       " 'beginning',\n",
       " 'believe',\n",
       " 'beneficial',\n",
       " 'best',\n",
       " 'better',\n",
       " 'beyond',\n",
       " 'big',\n",
       " 'bob',\n",
       " 'brent',\n",
       " 'broker',\n",
       " 'brokers',\n",
       " 'bumps',\n",
       " 'business',\n",
       " 'buy',\n",
       " 'buyer',\n",
       " 'buyers',\n",
       " 'buying',\n",
       " 'ca',\n",
       " 'call',\n",
       " 'called',\n",
       " 'calling',\n",
       " 'calls',\n",
       " 'calm',\n",
       " 'came',\n",
       " 'cannot',\n",
       " 'cant',\n",
       " 'capital',\n",
       " 'care',\n",
       " 'carrion',\n",
       " 'caused',\n",
       " 'causing',\n",
       " 'certainly',\n",
       " 'change',\n",
       " 'changed',\n",
       " 'changes',\n",
       " 'charge',\n",
       " 'check',\n",
       " 'chose',\n",
       " 'chris',\n",
       " 'circumstances',\n",
       " 'clear',\n",
       " 'clients',\n",
       " 'close',\n",
       " 'closed',\n",
       " 'closing',\n",
       " 'come',\n",
       " 'comes',\n",
       " 'comfortable',\n",
       " 'commented',\n",
       " 'commission',\n",
       " 'communicate',\n",
       " 'communicated',\n",
       " 'communication',\n",
       " 'companies',\n",
       " 'company',\n",
       " 'compared',\n",
       " 'competitive',\n",
       " 'complete',\n",
       " 'completed',\n",
       " 'completely',\n",
       " 'complicated',\n",
       " 'comps',\n",
       " 'concerns',\n",
       " 'confident',\n",
       " 'cons',\n",
       " 'considered',\n",
       " 'constant',\n",
       " 'contact',\n",
       " 'contacted',\n",
       " 'continue',\n",
       " 'continued',\n",
       " 'contract',\n",
       " 'conventional',\n",
       " 'conversation',\n",
       " 'conversations',\n",
       " 'cost',\n",
       " 'costs',\n",
       " 'could',\n",
       " 'couldn',\n",
       " 'couldnt',\n",
       " 'course',\n",
       " 'cover',\n",
       " 'credit',\n",
       " 'current',\n",
       " 'customer',\n",
       " 'customers',\n",
       " 'daily',\n",
       " 'dallas',\n",
       " 'date',\n",
       " 'day',\n",
       " 'days',\n",
       " 'deal',\n",
       " 'dealing',\n",
       " 'dealt',\n",
       " 'dean',\n",
       " 'decided',\n",
       " 'decision',\n",
       " 'definitely',\n",
       " 'delays',\n",
       " 'despite',\n",
       " 'detail',\n",
       " 'details',\n",
       " 'didnt',\n",
       " 'difference',\n",
       " 'different',\n",
       " 'difficult',\n",
       " 'directly',\n",
       " 'dlj',\n",
       " 'docs',\n",
       " 'documentation',\n",
       " 'documents',\n",
       " 'done',\n",
       " 'dont',\n",
       " 'dream',\n",
       " 'due',\n",
       " 'earlier',\n",
       " 'easier',\n",
       " 'easily',\n",
       " 'easy',\n",
       " 'effective',\n",
       " 'efficient',\n",
       " 'else',\n",
       " 'email',\n",
       " 'emailed',\n",
       " 'emails',\n",
       " 'encountered',\n",
       " 'end',\n",
       " 'ended',\n",
       " 'enough',\n",
       " 'ensure',\n",
       " 'entire',\n",
       " 'error',\n",
       " 'errors',\n",
       " 'escrow',\n",
       " 'especially',\n",
       " 'estate',\n",
       " 'etc',\n",
       " 'even',\n",
       " 'ever',\n",
       " 'every',\n",
       " 'everyone',\n",
       " 'everything',\n",
       " 'exactly',\n",
       " 'exceeded',\n",
       " 'excellent',\n",
       " 'expect',\n",
       " 'expectations',\n",
       " 'expected',\n",
       " 'experience',\n",
       " 'experienced',\n",
       " 'experiences',\n",
       " 'expertise',\n",
       " 'expired',\n",
       " 'explain',\n",
       " 'explained',\n",
       " 'explaining',\n",
       " 'express',\n",
       " 'extra',\n",
       " 'extremely',\n",
       " 'fact',\n",
       " 'failed',\n",
       " 'fall',\n",
       " 'family',\n",
       " 'fantastic',\n",
       " 'far',\n",
       " 'fast',\n",
       " 'feel',\n",
       " 'fees',\n",
       " 'felt',\n",
       " 'final',\n",
       " 'finally',\n",
       " 'financial',\n",
       " 'financing',\n",
       " 'find',\n",
       " 'fine',\n",
       " 'finish',\n",
       " 'first',\n",
       " 'five',\n",
       " 'follow',\n",
       " 'following',\n",
       " 'fortunate',\n",
       " 'forward',\n",
       " 'found',\n",
       " 'four',\n",
       " 'fred',\n",
       " 'free',\n",
       " 'friend',\n",
       " 'friendly',\n",
       " 'friends',\n",
       " 'front',\n",
       " 'frustrating',\n",
       " 'full',\n",
       " 'fully',\n",
       " 'funded',\n",
       " 'future',\n",
       " 'g',\n",
       " 'gave',\n",
       " 'get',\n",
       " 'getting',\n",
       " 'give',\n",
       " 'given',\n",
       " 'go',\n",
       " 'goals',\n",
       " 'going',\n",
       " 'good',\n",
       " 'goodlet',\n",
       " 'goods',\n",
       " 'got',\n",
       " 'great',\n",
       " 'guaranteed',\n",
       " 'guidance',\n",
       " 'guide',\n",
       " 'guy',\n",
       " 'guys',\n",
       " 'handled',\n",
       " 'hands',\n",
       " 'happen',\n",
       " 'happened',\n",
       " 'happening',\n",
       " 'happier',\n",
       " 'happy',\n",
       " 'hard',\n",
       " 'heard',\n",
       " 'help',\n",
       " 'helped',\n",
       " 'helpful',\n",
       " 'helping',\n",
       " 'hesitate',\n",
       " 'high',\n",
       " 'higher',\n",
       " 'highly',\n",
       " 'hold',\n",
       " 'home',\n",
       " 'homebuyer',\n",
       " 'homes',\n",
       " 'honest',\n",
       " 'honestly',\n",
       " 'hope',\n",
       " 'horrible',\n",
       " 'hour',\n",
       " 'hours',\n",
       " 'house',\n",
       " 'household',\n",
       " 'houses',\n",
       " 'however',\n",
       " 'hung',\n",
       " 'husband',\n",
       " 'i',\n",
       " 'id',\n",
       " 'im',\n",
       " 'immediately',\n",
       " 'impressed',\n",
       " 'including',\n",
       " 'income',\n",
       " 'industry',\n",
       " 'information',\n",
       " 'informative',\n",
       " 'informed',\n",
       " 'initial',\n",
       " 'initially',\n",
       " 'institution',\n",
       " 'instructed',\n",
       " 'interest',\n",
       " 'interested',\n",
       " 'involved',\n",
       " 'issues',\n",
       " 'items',\n",
       " 'ive',\n",
       " 'jason',\n",
       " 'jeremy',\n",
       " 'job',\n",
       " 'jocovic',\n",
       " 'joey',\n",
       " 'jon',\n",
       " 'june',\n",
       " 'k',\n",
       " 'keep',\n",
       " 'kept',\n",
       " 'kind',\n",
       " 'kirk',\n",
       " 'knew',\n",
       " 'know',\n",
       " 'knowing',\n",
       " 'knowledge',\n",
       " 'knowledgeable',\n",
       " 'known',\n",
       " 'kory',\n",
       " 'last',\n",
       " 'late',\n",
       " 'later',\n",
       " 'least',\n",
       " 'left',\n",
       " 'lender',\n",
       " 'lenders',\n",
       " 'lending',\n",
       " 'less',\n",
       " 'let',\n",
       " 'letter',\n",
       " 'life',\n",
       " 'like',\n",
       " 'line',\n",
       " 'list',\n",
       " 'little',\n",
       " 'll',\n",
       " 'loan',\n",
       " 'loans',\n",
       " 'local',\n",
       " 'lock',\n",
       " 'locked',\n",
       " 'long',\n",
       " 'longer',\n",
       " 'look',\n",
       " 'looking',\n",
       " 'lot',\n",
       " 'lower',\n",
       " 'made',\n",
       " 'mail',\n",
       " 'make',\n",
       " 'makes',\n",
       " 'making',\n",
       " 'man',\n",
       " 'manner',\n",
       " 'many',\n",
       " 'market',\n",
       " 'matt',\n",
       " 'matter',\n",
       " 'may',\n",
       " 'meet',\n",
       " 'mentioned',\n",
       " 'messages',\n",
       " 'met',\n",
       " 'mile',\n",
       " 'military',\n",
       " 'minimal',\n",
       " 'minutes',\n",
       " 'missed',\n",
       " 'mistake',\n",
       " 'money',\n",
       " 'month',\n",
       " 'monthly',\n",
       " 'months',\n",
       " 'mortgage',\n",
       " 'mortgages',\n",
       " 'mostly',\n",
       " 'move',\n",
       " 'moving',\n",
       " 'mr',\n",
       " 'much',\n",
       " 'multiple',\n",
       " 'name',\n",
       " 'nasb',\n",
       " 'nasbs',\n",
       " 'nc',\n",
       " 'necessary',\n",
       " 'need',\n",
       " 'needed',\n",
       " 'needs',\n",
       " 'never',\n",
       " 'new',\n",
       " 'next',\n",
       " 'night',\n",
       " 'none',\n",
       " 'north',\n",
       " 'notary',\n",
       " 'note',\n",
       " 'nothing',\n",
       " 'number',\n",
       " 'offer',\n",
       " 'offered',\n",
       " 'offers',\n",
       " 'office',\n",
       " 'officer',\n",
       " 'ok',\n",
       " 'old',\n",
       " 'one',\n",
       " 'online',\n",
       " 'option',\n",
       " 'options',\n",
       " 'oriented',\n",
       " 'original',\n",
       " 'originally',\n",
       " 'others',\n",
       " 'outstanding',\n",
       " 'overall',\n",
       " 'pacific',\n",
       " 'paid',\n",
       " 'painless',\n",
       " 'paper',\n",
       " 'paperwork',\n",
       " 'part',\n",
       " 'passionate',\n",
       " 'past',\n",
       " 'patient',\n",
       " 'patiently',\n",
       " 'patrick',\n",
       " 'pay',\n",
       " 'paying',\n",
       " 'payment',\n",
       " 'payments',\n",
       " 'people',\n",
       " 'person',\n",
       " 'personal',\n",
       " 'personally',\n",
       " 'peter',\n",
       " 'phone',\n",
       " 'plan',\n",
       " 'planned',\n",
       " 'pleasant',\n",
       " 'please',\n",
       " 'pleased',\n",
       " 'pleasure',\n",
       " 'plus',\n",
       " 'point',\n",
       " 'poor',\n",
       " 'position',\n",
       " 'positive',\n",
       " 'possible',\n",
       " 'potential',\n",
       " 'preapproval',\n",
       " 'pretty',\n",
       " 'previous',\n",
       " 'problem',\n",
       " 'problems',\n",
       " 'process',\n",
       " 'processing',\n",
       " 'processor',\n",
       " 'product',\n",
       " 'professional',\n",
       " 'professionalism',\n",
       " 'professionally',\n",
       " 'promised',\n",
       " 'prompt',\n",
       " 'promptly',\n",
       " 'properties',\n",
       " 'property',\n",
       " 'pros',\n",
       " 'provide',\n",
       " 'provided',\n",
       " 'pulled',\n",
       " 'purchase',\n",
       " 'purchased',\n",
       " 'purchasing',\n",
       " 'put',\n",
       " 'question',\n",
       " 'questions',\n",
       " 'quick',\n",
       " 'quickly',\n",
       " 'quite',\n",
       " 'quotes',\n",
       " 'ran',\n",
       " 'rate',\n",
       " 'rates',\n",
       " 'reach',\n",
       " 'reached',\n",
       " 'read',\n",
       " 'ready',\n",
       " 'real',\n",
       " 'really',\n",
       " 'realtor',\n",
       " 'receive',\n",
       " 'received',\n",
       " 'recommend',\n",
       " 'recommended',\n",
       " 'record',\n",
       " 'refi',\n",
       " 'refinance',\n",
       " 'refinanced',\n",
       " 'refinancing',\n",
       " 'regulations',\n",
       " 'reliance',\n",
       " 'rep',\n",
       " 'representative',\n",
       " 'request',\n",
       " 'requested',\n",
       " 'requests',\n",
       " 'required',\n",
       " 'respond',\n",
       " 'responded',\n",
       " 'response',\n",
       " 'responses',\n",
       " 'responsive',\n",
       " 'responsiveness',\n",
       " 'result',\n",
       " 'returned',\n",
       " 'review',\n",
       " 'reviews',\n",
       " 'rick',\n",
       " 'right',\n",
       " 'robert',\n",
       " 'rude',\n",
       " 's',\n",
       " 'said',\n",
       " 'sale',\n",
       " 'satisfied',\n",
       " 'save',\n",
       " 'saved',\n",
       " 'savings',\n",
       " 'say',\n",
       " 'saying',\n",
       " 'scheduled',\n",
       " 'score',\n",
       " 'second',\n",
       " 'see',\n",
       " 'seem',\n",
       " 'seemed',\n",
       " 'selected',\n",
       " 'sell',\n",
       " 'send',\n",
       " 'sending',\n",
       " 'sent',\n",
       " 'service',\n",
       " 'services',\n",
       " 'set',\n",
       " 'several',\n",
       " 'show',\n",
       " 'showed',\n",
       " 'showing',\n",
       " 'side',\n",
       " 'sign',\n",
       " 'signed',\n",
       " 'simple',\n",
       " 'since',\n",
       " 'situation',\n",
       " 'skills',\n",
       " 'slow',\n",
       " 'small',\n",
       " 'smooth',\n",
       " 'smoothly',\n",
       " 'someone',\n",
       " 'something',\n",
       " 'special',\n",
       " 'specifically',\n",
       " 'speed',\n",
       " 'spent',\n",
       " 'spoke',\n",
       " 'staff',\n",
       " 'stage',\n",
       " 'star',\n",
       " 'stars',\n",
       " 'start',\n",
       " 'started',\n",
       " 'state',\n",
       " 'status',\n",
       " 'stayed',\n",
       " 'steer',\n",
       " 'step',\n",
       " 'stephanie',\n",
       " 'steve',\n",
       " 'steven',\n",
       " 'still',\n",
       " 'stopped',\n",
       " 'stress',\n",
       " 'stressful',\n",
       " 'successful',\n",
       " 'suggested',\n",
       " 'super',\n",
       " 'support',\n",
       " 'sure',\n",
       " 'surprises',\n",
       " 'system',\n",
       " 't',\n",
       " 'take',\n",
       " 'taken',\n",
       " 'talk',\n",
       " 'talked',\n",
       " 'talking',\n",
       " 'team',\n",
       " 'tell',\n",
       " 'telling',\n",
       " 'terms',\n",
       " 'text',\n",
       " 'th',\n",
       " 'thank',\n",
       " 'thankful',\n",
       " 'thanks',\n",
       " 'thats',\n",
       " 'thing',\n",
       " 'things',\n",
       " 'thorough',\n",
       " 'thoroughly',\n",
       " 'though',\n",
       " 'thought',\n",
       " 'thousands',\n",
       " 'three',\n",
       " 'throughout',\n",
       " 'thru',\n",
       " 'time',\n",
       " 'timely',\n",
       " 'times',\n",
       " 'together',\n",
       " 'told',\n",
       " 'took',\n",
       " 'top',\n",
       " 'total',\n",
       " 'touch',\n",
       " 'track',\n",
       " 'transaction',\n",
       " 'tree',\n",
       " 'tried',\n",
       " 'triumph',\n",
       " 'true',\n",
       " 'truly',\n",
       " 'trusted',\n",
       " 'trying',\n",
       " 'twice',\n",
       " 'two',\n",
       " 'types',\n",
       " 'ultimately',\n",
       " 'understand',\n",
       " 'understood',\n",
       " 'unless',\n",
       " 'unlike',\n",
       " 'unpleasant',\n",
       " 'unprofessional',\n",
       " 'updates',\n",
       " 'upfront',\n",
       " 'upon',\n",
       " 'us',\n",
       " 'use',\n",
       " 'used',\n",
       " 'using',\n",
       " 'va',\n",
       " 'vacation',\n",
       " 'various',\n",
       " 've',\n",
       " 'veteran',\n",
       " 'via',\n",
       " 'walk',\n",
       " 'walked',\n",
       " 'want',\n",
       " 'wanted',\n",
       " 'wasnt',\n",
       " 'waste',\n",
       " 'way',\n",
       " 'waymire',\n",
       " 'we',\n",
       " 'website',\n",
       " 'week',\n",
       " 'weekends',\n",
       " 'weeks',\n",
       " 'well',\n",
       " 'went',\n",
       " 'werent',\n",
       " 'weve',\n",
       " 'whatever',\n",
       " 'whole',\n",
       " 'wife',\n",
       " 'willing',\n",
       " 'within',\n",
       " 'without',\n",
       " 'woman',\n",
       " 'wonderful',\n",
       " 'word',\n",
       " 'work',\n",
       " 'worked',\n",
       " 'working',\n",
       " 'works',\n",
       " 'worth',\n",
       " 'would',\n",
       " 'wouldnt',\n",
       " 'writing',\n",
       " 'written',\n",
       " 'wrong',\n",
       " 'wyndham',\n",
       " 'year',\n",
       " 'years',\n",
       " 'yet']"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_vect.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtm1=pd.DataFrame(dtm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtm1.columns=count_vect.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>aaron</th>\n",
       "      <th>ability</th>\n",
       "      <th>able</th>\n",
       "      <th>absolutely</th>\n",
       "      <th>accept</th>\n",
       "      <th>accommodating</th>\n",
       "      <th>account</th>\n",
       "      <th>accurate</th>\n",
       "      <th>achieve</th>\n",
       "      <th>across</th>\n",
       "      <th>...</th>\n",
       "      <th>worth</th>\n",
       "      <th>would</th>\n",
       "      <th>wouldnt</th>\n",
       "      <th>writing</th>\n",
       "      <th>written</th>\n",
       "      <th>wrong</th>\n",
       "      <th>wyndham</th>\n",
       "      <th>year</th>\n",
       "      <th>years</th>\n",
       "      <th>yet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>373</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>374</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>375</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>376</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>377</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>378 rows × 732 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     aaron  ability  able  absolutely  accept  accommodating  account  \\\n",
       "0        0        0     0           0       1              0        0   \n",
       "1        0        0     0           0       0              0        0   \n",
       "2        0        0     0           0       0              0        0   \n",
       "3        0        0     0           0       1              0        0   \n",
       "4        0        0     0           0       0              0        0   \n",
       "..     ...      ...   ...         ...     ...            ...      ...   \n",
       "373      0        0     0           0       0              0        0   \n",
       "374      0        0     0           0       0              0        0   \n",
       "375      0        0     0           0       0              0        0   \n",
       "376      0        0     0           0       0              0        0   \n",
       "377      0        0     0           0       0              0        0   \n",
       "\n",
       "     accurate  achieve  across  ...  worth  would  wouldnt  writing  written  \\\n",
       "0           0        0       0  ...      0      0        1        0        0   \n",
       "1           0        0       0  ...      0      0        0        0        0   \n",
       "2           0        0       0  ...      0      0        0        0        0   \n",
       "3           0        0       0  ...      0      0        1        0        0   \n",
       "4           0        0       0  ...      0      0        0        0        0   \n",
       "..        ...      ...     ...  ...    ...    ...      ...      ...      ...   \n",
       "373         0        0       0  ...      0      0        0        0        0   \n",
       "374         0        0       0  ...      0      1        0        0        0   \n",
       "375         0        0       0  ...      0      0        0        0        0   \n",
       "376         0        0       0  ...      0      0        0        0        0   \n",
       "377         0        0       0  ...      0      0        0        0        0   \n",
       "\n",
       "     wrong  wyndham  year  years  yet  \n",
       "0        0        0     0      1    0  \n",
       "1        0        0     0      0    0  \n",
       "2        0        0     0      0    0  \n",
       "3        0        0     0      1    0  \n",
       "4        0        0     0      0    0  \n",
       "..     ...      ...   ...    ...  ...  \n",
       "373      0        0     0      0    0  \n",
       "374      0        0     0      0    0  \n",
       "375      0        0     0      0    0  \n",
       "376      0        0     0      0    0  \n",
       "377      0        0     0      0    0  \n",
       "\n",
       "[378 rows x 732 columns]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dtm1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vectorization (count, tfidf) for both train & test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train\n",
    "count_vect = CountVectorizer(analyzer='word', \n",
    "                             token_pattern=r'\\w{1,}', \n",
    "                             ngram_range=(1, 1 ), \n",
    "                             min_df=5, \n",
    "                             encoding='latin-1' , \n",
    "                             max_features=800)\n",
    "\n",
    "xtrain_count = count_vect.fit_transform(X_train)\n",
    "\n",
    "tfidf_transformer = TfidfTransformer()\n",
    "X_train_tfidf = tfidf_transformer.fit_transform(xtrain_count)\n",
    "\n",
    "#Test\n",
    "#count_vect = CountVectorizer()\n",
    "xtest_count = count_vect.transform(X_test)\n",
    "\n",
    "#tfidf_transformer = TfidfTransformer()\n",
    "X_test_tfidf = tfidf_transformer.transform(xtest_count)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtm2=pd.DataFrame(X_train_tfidf.toarray(), columns=count_vect.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>aaron</th>\n",
       "      <th>able</th>\n",
       "      <th>absolutely</th>\n",
       "      <th>accept</th>\n",
       "      <th>accommodating</th>\n",
       "      <th>account</th>\n",
       "      <th>accurate</th>\n",
       "      <th>across</th>\n",
       "      <th>actual</th>\n",
       "      <th>adam</th>\n",
       "      <th>...</th>\n",
       "      <th>working</th>\n",
       "      <th>works</th>\n",
       "      <th>would</th>\n",
       "      <th>wouldnt</th>\n",
       "      <th>writing</th>\n",
       "      <th>wrong</th>\n",
       "      <th>wyndham</th>\n",
       "      <th>year</th>\n",
       "      <th>years</th>\n",
       "      <th>yet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.133259</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.123737</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.096250</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.194406</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.130702</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.121363</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.094403</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 596 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   aaron  able  absolutely    accept  accommodating  account  accurate  \\\n",
       "0    0.0   0.0         0.0  0.133259            0.0      0.0       0.0   \n",
       "1    0.0   0.0         0.0  0.000000            0.0      0.0       0.0   \n",
       "2    0.0   0.0         0.0  0.000000            0.0      0.0       0.0   \n",
       "3    0.0   0.0         0.0  0.130702            0.0      0.0       0.0   \n",
       "4    0.0   0.0         0.0  0.000000            0.0      0.0       0.0   \n",
       "\n",
       "   across  actual  adam  ...   working  works  would   wouldnt  writing  \\\n",
       "0     0.0     0.0   0.0  ...  0.000000    0.0    0.0  0.123737      0.0   \n",
       "1     0.0     0.0   0.0  ...  0.000000    0.0    0.0  0.000000      0.0   \n",
       "2     0.0     0.0   0.0  ...  0.194406    0.0    0.0  0.000000      0.0   \n",
       "3     0.0     0.0   0.0  ...  0.000000    0.0    0.0  0.121363      0.0   \n",
       "4     0.0     0.0   0.0  ...  0.000000    0.0    0.0  0.000000      0.0   \n",
       "\n",
       "   wrong  wyndham  year     years  yet  \n",
       "0    0.0      0.0   0.0  0.096250  0.0  \n",
       "1    0.0      0.0   0.0  0.000000  0.0  \n",
       "2    0.0      0.0   0.0  0.000000  0.0  \n",
       "3    0.0      0.0   0.0  0.094403  0.0  \n",
       "4    0.0      0.0   0.0  0.000000  0.0  \n",
       "\n",
       "[5 rows x 596 columns]"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dtm2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ngram level tf-idf \n",
    "tfidf_vect_ngram = TfidfVectorizer(analyzer='word', token_pattern='\\w{1,}', ngram_range=(1, 2), max_features=800)\n",
    "tfidf_vect_ngram.fit(df['Reviews'])\n",
    "xtrain_tfidf_ngram =  tfidf_vect_ngram.transform(X_train)\n",
    "xtest_tfidf_ngram =  tfidf_vect_ngram.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create user defined function for train the models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(classifier, feature_vector_train, label, feature_vector_valid,  valid_y):\n",
    "    # fit the training dataset on the classifier\n",
    "    classifier.fit(feature_vector_train, label)\n",
    "    \n",
    "    # predict the labels on validation dataset\n",
    "    predictions = classifier.predict(feature_vector_valid)\n",
    "    \n",
    "    return metrics.accuracy_score(classifier.predict(feature_vector_train), label), metrics.accuracy_score(predictions, valid_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building different models with different vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frequency of unique values of the said array:\n",
      "[[  1   5]\n",
      " [ 70 308]]\n"
     ]
    }
   ],
   "source": [
    "unique_elements, counts_elements = np.unique(y_train, return_counts=True)\n",
    "print(\"Frequency of unique values of the said array:\")\n",
    "print(np.asarray((unique_elements, counts_elements)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frequency of unique values of the said array:\n",
      "[[  1   5]\n",
      " [308 308]]\n"
     ]
    }
   ],
   "source": [
    "ros = RandomOverSampler(random_state=123)\n",
    "\n",
    "X_train_tfidf_os, y_train_tfidf_os = ros.fit_sample(X_train_tfidf, y_train)\n",
    "\n",
    "X_train_cnt_os, y_train_cnt_os = ros.fit_sample(xtrain_count, y_train)\n",
    "\n",
    "X_train_tfidf_ngram_os, y_train_tfidf_ngram_os = ros.fit_sample(xtrain_tfidf_ngram, y_train)\n",
    "\n",
    "unique_elements, counts_elements = np.unique(y_train_tfidf_os, return_counts=True)\n",
    "print(\"Frequency of unique values of the said array:\")\n",
    "print(np.asarray((unique_elements, counts_elements)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NB  for L1, Count Vectors:  (0.9756493506493507, 0.952755905511811)\n",
      "NB  for L1, WordLevel TF-IDF:  (0.9724025974025974, 0.9606299212598425)\n",
      "NB  for L1, N-Gram Vectors:  (0.974025974025974, 0.9448818897637795)\n"
     ]
    }
   ],
   "source": [
    "#Naive Bayes\n",
    "# Naive Bayes on TF-IDF\n",
    "accuracy_L1 = train_model(naive_bayes.MultinomialNB(), X_train_tfidf_os, y_train_tfidf_os, X_test_tfidf, y_test)\n",
    "print(\"NB  for L1, Count Vectors: \", accuracy_L1)\n",
    "\n",
    "# Naive Bayes on Word Level TF IDF Vectors\n",
    "accuracy_L1 = train_model(naive_bayes.MultinomialNB(), X_train_cnt_os, y_train_cnt_os, xtest_count, y_test)\n",
    "print(\"NB  for L1, WordLevel TF-IDF: \", accuracy_L1)\n",
    "\n",
    "# Naive Bayes on Ngram Level TF IDF Vectors\n",
    "accuracy_L1 = train_model(naive_bayes.MultinomialNB(), X_train_tfidf_ngram_os, y_train_tfidf_ngram_os, xtest_tfidf_ngram, y_test)\n",
    "print(\"NB  for L1, N-Gram Vectors: \", accuracy_L1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR  for L1, Count Vectors:  (0.9837662337662337, 0.968503937007874)\n",
      "LR  for L1, WordLevel TF-IDF:  (0.9983766233766234, 0.9763779527559056)\n",
      "LR  for L1, N-Gram Vectors:  (0.9756493506493507, 0.9606299212598425)\n"
     ]
    }
   ],
   "source": [
    "#Logistic Regression\n",
    "# Logistic Regression on Count Vectors and TF-IDF\n",
    "accuracy_L1 = train_model(LogisticRegression(), X_train_tfidf_os, y_train_tfidf_os, X_test_tfidf, y_test)\n",
    "print(\"LR  for L1, Count Vectors: \", accuracy_L1)\n",
    "\n",
    "\n",
    "\n",
    "# Logistic Regression on Word Level TF IDF Vectors\n",
    "accuracy_L1 = train_model(LogisticRegression(), X_train_cnt_os, y_train_cnt_os, xtest_count, y_test)\n",
    "print(\"LR  for L1, WordLevel TF-IDF: \", accuracy_L1)\n",
    "\n",
    "\n",
    "\n",
    "# Logistic Regression on Ngram Level TF IDF Vectors\n",
    "accuracy_L1 = train_model(LogisticRegression(), X_train_tfidf_ngram_os, y_train_tfidf_ngram_os, xtest_tfidf_ngram, y_test)\n",
    "print(\"LR  for L1, N-Gram Vectors: \", accuracy_L1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'y_pred_rfc' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-72-ec5ed5fd4aac>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconfusion_matrix\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred_rfc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'y_pred_rfc' is not defined"
     ]
    }
   ],
   "source": [
    "print(metrics.confusion_matrix(y_test, y_pred_rfc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVC  for L1, Count Vectors:  (0.9983766233766234, 0.937007874015748)\n",
      "SVC  for L1, WordLevel TF-IDF:  (0.9756493506493507, 0.9448818897637795)\n",
      "SVC  for L1, N-Gram Vectors:  (0.9983766233766234, 0.9448818897637795)\n"
     ]
    }
   ],
   "source": [
    "#Linear SVC\n",
    "# Linear SVC on Count Vectors and TF-IDF\n",
    "accuracy_L1 = train_model(SVC(), X_train_tfidf_os, y_train_tfidf_os, X_test_tfidf, y_test)\n",
    "print(\"SVC  for L1, Count Vectors: \", accuracy_L1)\n",
    "\n",
    "\n",
    "\n",
    "# Linear SVC on Word Level TF IDF Vectors\n",
    "accuracy_L1 = train_model(SVC(), X_train_cnt_os, y_train_cnt_os, xtest_count, y_test)\n",
    "print(\"SVC  for L1, WordLevel TF-IDF: \", accuracy_L1)\n",
    "\n",
    "\n",
    "\n",
    "# Linear SVC on Ngram Level TF IDF Vectors\n",
    "accuracy_L1 = train_model(SVC(), X_train_tfidf_ngram_os, y_train_tfidf_ngram_os, xtest_tfidf_ngram, y_test)\n",
    "print(\"SVC  for L1, N-Gram Vectors: \", accuracy_L1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adding Features to a Document-Term Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a DataFrame that only contains the 5-star and 1-star reviews\n",
    "\n",
    "bankreviews['Stars'] = np.where(bankreviews['Stars']>3, 5, np.where(bankreviews['Stars']<3,1,3))\n",
    "\n",
    "bankreviews = bankreviews[(bankreviews.Stars==5) | (bankreviews.Stars==1)]\n",
    "\n",
    "# define X and y\n",
    "feature_cols = ['Reviews', 'sentiment', 'BankName']\n",
    "X = bankreviews[feature_cols]\n",
    "y = bankreviews.Stars\n",
    "\n",
    "# split into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(378, 627)\n",
      "(127, 627)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(378, 2)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# use CountVectorizer with text column only\n",
    "vect = TfidfVectorizer(lowercase=True, stop_words='english', max_features=1000, min_df=5, ngram_range=(1, 2))\n",
    "X_train_dtm = vect.fit_transform(X_train.Reviews)\n",
    "X_test_dtm = vect.transform(X_test.Reviews)\n",
    "print(X_train_dtm.shape)\n",
    "print(X_test_dtm.shape)\n",
    "\n",
    "# shape of other four feature columns\n",
    "X_train.drop('Reviews', axis=1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(378, 2438)\n",
      "(127, 2438)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(378, 2)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# use CountVectorizer with text column only\n",
    "vect = CountVectorizer()\n",
    "X_train_dtm = vect.fit_transform(X_train.Reviews)\n",
    "X_test_dtm = vect.transform(X_test.Reviews)\n",
    "print(X_train_dtm.shape)\n",
    "print(X_test_dtm.shape)\n",
    "\n",
    "# shape of other four feature columns\n",
    "X_train.drop('Reviews', axis=1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "drop not found",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-97-ce7e7d7cf6b5>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# cast other feature columns to float and convert to a sparse matrix\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mextra\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msparse\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcsr_matrix\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Reviews'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfloat\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mextra\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;31m# combine sparse matrices\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\scipy\\sparse\\base.py\u001b[0m in \u001b[0;36m__getattr__\u001b[1;34m(self, attr)\u001b[0m\n\u001b[0;32m    689\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgetnnz\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    690\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 691\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mattr\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m\" not found\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    692\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    693\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mtranspose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxes\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: drop not found"
     ]
    }
   ],
   "source": [
    "# cast other feature columns to float and convert to a sparse matrix\n",
    "extra = sparse.csr_matrix(X_train.drop('Reviews', axis=1).astype(float))\n",
    "extra.shape\n",
    "\n",
    "# combine sparse matrices\n",
    "X_train_dtm_extra = sparse.hstack((X_train_dtm, extra))\n",
    "X_train_dtm_extra.shape\n",
    "\n",
    "# repeat for testing set\n",
    "extra = sparse.csr_matrix(X_test.drop('Reviews', axis=1).astype(float))\n",
    "X_test_dtm_extra = sparse.hstack((X_test_dtm, extra))\n",
    "X_test_dtm_extra.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.952755905511811\n",
      "0.9101960784313725\n"
     ]
    }
   ],
   "source": [
    "# use logistic regression with text column only\n",
    "logreg = LogisticRegression(C=1e9)\n",
    "logreg.fit(X_train_dtm, y_train)\n",
    "y_pred_class = logreg.predict(X_test_dtm)\n",
    "print(metrics.accuracy_score(y_test, y_pred_class))\n",
    "print(metrics.roc_auc_score(y_test, y_pred_class))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_train_dtm_extra' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-98-3f05e56c3ff2>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# use logistic regression with all features\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mlogreg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mLogisticRegression\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mC\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1e9\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mlogreg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train_dtm_extra\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0my_pred_class\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlogreg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test_dtm_extra\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maccuracy_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred_class\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'X_train_dtm_extra' is not defined"
     ]
    }
   ],
   "source": [
    "# use logistic regression with all features\n",
    "logreg = LogisticRegression(C=1e9)\n",
    "logreg.fit(X_train_dtm_extra, y_train)\n",
    "y_pred_class = logreg.predict(X_test_dtm_extra)\n",
    "print(metrics.accuracy_score(y_test, y_pred_class))\n",
    "print(metrics.roc_auc_score(y_test, y_pred_class))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Topic Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Stars</th>\n",
       "      <th>Reviews</th>\n",
       "      <th>BankName</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>Great job, Wyndham Capital! Each person was pr...</td>\n",
       "      <td>Wyndham Capital Mortgage</td>\n",
       "      <td>0.533333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>Matthew Richardson is professional and helpful...</td>\n",
       "      <td>Wyndham Capital Mortgage</td>\n",
       "      <td>0.453333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>We had a past experience with Wyndham Mortgage...</td>\n",
       "      <td>Wyndham Capital Mortgage</td>\n",
       "      <td>-0.033231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>We have been dealing with Brad Thomka from the...</td>\n",
       "      <td>Wyndham Capital Mortgage</td>\n",
       "      <td>0.093740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>I can't express how grateful I am for the supp...</td>\n",
       "      <td>Wyndham Capital Mortgage</td>\n",
       "      <td>0.125000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Stars                                            Reviews  \\\n",
       "0      5  Great job, Wyndham Capital! Each person was pr...   \n",
       "1      5  Matthew Richardson is professional and helpful...   \n",
       "2      5  We had a past experience with Wyndham Mortgage...   \n",
       "3      5  We have been dealing with Brad Thomka from the...   \n",
       "4      5  I can't express how grateful I am for the supp...   \n",
       "\n",
       "                   BankName  sentiment  \n",
       "0  Wyndham Capital Mortgage   0.533333  \n",
       "1  Wyndham Capital Mortgage   0.453333  \n",
       "2  Wyndham Capital Mortgage  -0.033231  \n",
       "3  Wyndham Capital Mortgage   0.093740  \n",
       "4  Wyndham Capital Mortgage   0.125000  "
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bankreviews.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = bankreviews\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "#make a copy of columns I need from raw data\n",
    "df1 = data.iloc[:, [0,1,2]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Stars</th>\n",
       "      <th>Reviews</th>\n",
       "      <th>BankName</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>Great job, Wyndham Capital! Each person was pr...</td>\n",
       "      <td>Wyndham Capital Mortgage</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>Matthew Richardson is professional and helpful...</td>\n",
       "      <td>Wyndham Capital Mortgage</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>We had a past experience with Wyndham Mortgage...</td>\n",
       "      <td>Wyndham Capital Mortgage</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>We have been dealing with Brad Thomka from the...</td>\n",
       "      <td>Wyndham Capital Mortgage</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>I can't express how grateful I am for the supp...</td>\n",
       "      <td>Wyndham Capital Mortgage</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Stars                                            Reviews  \\\n",
       "0      5  Great job, Wyndham Capital! Each person was pr...   \n",
       "1      5  Matthew Richardson is professional and helpful...   \n",
       "2      5  We had a past experience with Wyndham Mortgage...   \n",
       "3      5  We have been dealing with Brad Thomka from the...   \n",
       "4      5  I can't express how grateful I am for the supp...   \n",
       "\n",
       "                   BankName  \n",
       "0  Wyndham Capital Mortgage  \n",
       "1  Wyndham Capital Mortgage  \n",
       "2  Wyndham Capital Mortgage  \n",
       "3  Wyndham Capital Mortgage  \n",
       "4  Wyndham Capital Mortgage  "
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Score</th>\n",
       "      <th>Text</th>\n",
       "      <th>BankName</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>Great job, Wyndham Capital! Each person was pr...</td>\n",
       "      <td>Wyndham Capital Mortgage</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>Matthew Richardson is professional and helpful...</td>\n",
       "      <td>Wyndham Capital Mortgage</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>We had a past experience with Wyndham Mortgage...</td>\n",
       "      <td>Wyndham Capital Mortgage</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>We have been dealing with Brad Thomka from the...</td>\n",
       "      <td>Wyndham Capital Mortgage</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>I can't express how grateful I am for the supp...</td>\n",
       "      <td>Wyndham Capital Mortgage</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Score                                               Text  \\\n",
       "0      5  Great job, Wyndham Capital! Each person was pr...   \n",
       "1      5  Matthew Richardson is professional and helpful...   \n",
       "2      5  We had a past experience with Wyndham Mortgage...   \n",
       "3      5  We have been dealing with Brad Thomka from the...   \n",
       "4      5  I can't express how grateful I am for the supp...   \n",
       "\n",
       "                   BankName  \n",
       "0  Wyndham Capital Mortgage  \n",
       "1  Wyndham Capital Mortgage  \n",
       "2  Wyndham Capital Mortgage  \n",
       "3  Wyndham Capital Mortgage  \n",
       "4  Wyndham Capital Mortgage  "
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1 = df1.rename(columns={\"Stars\":\"Score\",\"Reviews\":\"Text\"})\n",
    "df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1['Bad'] = np.where(df1.Score<=4,1,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Score</th>\n",
       "      <th>Text</th>\n",
       "      <th>BankName</th>\n",
       "      <th>Bad</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>Great job, Wyndham Capital! Each person was pr...</td>\n",
       "      <td>Wyndham Capital Mortgage</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>Matthew Richardson is professional and helpful...</td>\n",
       "      <td>Wyndham Capital Mortgage</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>We had a past experience with Wyndham Mortgage...</td>\n",
       "      <td>Wyndham Capital Mortgage</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>We have been dealing with Brad Thomka from the...</td>\n",
       "      <td>Wyndham Capital Mortgage</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>I can't express how grateful I am for the supp...</td>\n",
       "      <td>Wyndham Capital Mortgage</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Score                                               Text  \\\n",
       "0      5  Great job, Wyndham Capital! Each person was pr...   \n",
       "1      5  Matthew Richardson is professional and helpful...   \n",
       "2      5  We had a past experience with Wyndham Mortgage...   \n",
       "3      5  We have been dealing with Brad Thomka from the...   \n",
       "4      5  I can't express how grateful I am for the supp...   \n",
       "\n",
       "                   BankName  Bad  \n",
       "0  Wyndham Capital Mortgage    0  \n",
       "1  Wyndham Capital Mortgage    0  \n",
       "2  Wyndham Capital Mortgage    0  \n",
       "3  Wyndham Capital Mortgage    0  \n",
       "4  Wyndham Capital Mortgage    0  "
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert text to lowercase\n",
    "df1.loc[:, 'Text'] = df1['Text'].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TfidfVectorizer(max_df=0.95, min_df=0.05, stop_words='english')"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get the tf-idf table \n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "vectorizer = TfidfVectorizer(min_df = 0.05, max_df=0.95,\n",
    "                             ngram_range=(1, 1), \n",
    "                             stop_words='english')\n",
    "vectorizer.fit(df1['Text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a training data\n",
    "X_train = vectorizer.transform(df1['Text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Apply TfidfVectorizer to review text\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we create a kmeans model\n",
    "model = KMeans(n_clusters=6, \n",
    "               init='k-means++', \n",
    "               max_iter=100, n_init=1,random_state=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KMeans(max_iter=100, n_clusters=6, n_init=1, random_state=5)"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# apply the model on this prepared data\n",
    "res = model.fit(X_train)\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting the vocalbulary as well as cluster centers\n",
    "# Firstly, set of words from the tf-idf itself\n",
    "vocab = vectorizer.get_feature_names()\n",
    "vocab = np.array(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Then, the cluster centers from the model fit that we stored on res\n",
    "cluster_centers = np.array(res.cluster_centers_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 52,  47,  25,  24,  48,  22,  57,  64,  65,  68,  17,  74,  80,\n",
       "        40,  14,  82,  83,  10,  86,  91,   7,  93,  96,   3,   2,   1,\n",
       "        81,  29,  99, 105,  13,  34,  61,  59,  16,  15,  41,  18,  19,\n",
       "        97,  63,  73,  71,  72,  85,  11,  60,  84,  31,  66, 104,   6,\n",
       "        54,  45,   9,  58,  77,  21,  32,  78,  37, 103,  95,  33,  36,\n",
       "        98,  28, 101,  87,  43,  38,  88,  39,  26, 100,  46,   8,  79,\n",
       "        62,  20,  30,  49,  53,  90,  94,  92, 102,  55,   5,  42,  51,\n",
       "        89,  67,  69,  70,  76,  50,   4,  75,  44,  27,  12,  56,  23,\n",
       "        35,   0], dtype=int64)"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#x=np.array((0.1,10,0.05,1.5))\n",
    "#print(x)\n",
    "#print(x.argsort())\n",
    "res.cluster_centers_[0].argsort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sorting the cluster centers\n",
    "sorted_vals = [res.cluster_centers_[i].argsort() for i in range(0,np.shape(res.cluster_centers_)[0])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'end', 'didn', 'getting', 'helpful', 'beginning', 'know', 'closed', 'loan', 'rate', 'able'}\n",
      "{'mortgage', 'looking', 'service', 'recommend', 'process', 'loan', 'company', 'customer', 'provided', 'nasb'}\n",
      "{'officer', 'knowledgeable', 'best', 'thank', 've', 'loan', 'process', 'responsive', 'great', 'worked'}\n",
      "{'pleasure', 'easy', 'closing', 'great', 'process', 'got', 'work', 'time', 'nasb', 'team'}\n",
      "{'hard', 'recommend', 'friendly', 'loan', 'professional', 'questions', 'responsive', 'highly', 'worked', 'team'}\n",
      "{'did', 'helpful', 'closing', 'process', 'loan', 'home', 'questions', 'rate', 'time', 'read'}\n"
     ]
    }
   ],
   "source": [
    "# get top 10 words from that cluster\n",
    "words=set()\n",
    "for i in range(len(res.cluster_centers_)):\n",
    "    words = set(vocab[sorted_vals[i][-10:]])\n",
    "    print(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "words=list(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Score</th>\n",
       "      <th>Text</th>\n",
       "      <th>BankName</th>\n",
       "      <th>Bad</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cluster</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>29</td>\n",
       "      <td>29</td>\n",
       "      <td>29</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>105</td>\n",
       "      <td>105</td>\n",
       "      <td>105</td>\n",
       "      <td>105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>69</td>\n",
       "      <td>69</td>\n",
       "      <td>69</td>\n",
       "      <td>69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>90</td>\n",
       "      <td>90</td>\n",
       "      <td>90</td>\n",
       "      <td>90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>57</td>\n",
       "      <td>57</td>\n",
       "      <td>57</td>\n",
       "      <td>57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>155</td>\n",
       "      <td>155</td>\n",
       "      <td>155</td>\n",
       "      <td>155</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Score  Text  BankName  Bad\n",
       "cluster                            \n",
       "0           29    29        29   29\n",
       "1          105   105       105  105\n",
       "2           69    69        69   69\n",
       "3           90    90        90   90\n",
       "4           57    57        57   57\n",
       "5          155   155       155  155"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# how many observations are in each cluster\n",
    "\n",
    "df1['cluster'] = model.labels_\n",
    "df1.groupby('cluster').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Score</th>\n",
       "      <th>Bad</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cluster</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4.172414</td>\n",
       "      <td>0.206897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3.895238</td>\n",
       "      <td>0.276190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.710145</td>\n",
       "      <td>0.072464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.600000</td>\n",
       "      <td>0.100000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.859649</td>\n",
       "      <td>0.035088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>3.864516</td>\n",
       "      <td>0.283871</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Score       Bad\n",
       "cluster                    \n",
       "0        4.172414  0.206897\n",
       "1        3.895238  0.276190\n",
       "2        4.710145  0.072464\n",
       "3        4.600000  0.100000\n",
       "4        4.859649  0.035088\n",
       "5        3.864516  0.283871"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# what does each cluster look like\n",
    "df1.groupby('cluster').mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Topic Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train a LDA Model\n",
    "\n",
    "from sklearn import decomposition\n",
    "\n",
    "lda_model = decomposition.LatentDirichletAllocation(n_components=10, learning_method='online', max_iter=50)\n",
    "X_topics = lda_model.fit_transform(X_train)\n",
    "topic_word = lda_model.components_ \n",
    "vocab = vectorizer.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['great process mortgage quick pleasure work definitely questions knowledgeable easy',\n",
       " 'closing rate said lender told did loan weeks day credit',\n",
       " 'step time way helpful make able helped loan took home',\n",
       " 'got best work beginning answered couldn end calls thanks really',\n",
       " 'thank loan communication happy future good sure business officer house',\n",
       " 'process team service great loan home time best professional recommend',\n",
       " 'responsive good extremely smooth process feel helpful really work service',\n",
       " 'company loan calls mortgage phone officer refinance customer times things',\n",
       " 'home amazing recommend hard helped experience working highly closed thanks',\n",
       " 'weeks refinancing later closed told home company make recommend closing']"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# view the topic models\n",
    "n_top_words = 10\n",
    "topic_summaries = []\n",
    "for i, topic_dist in enumerate(topic_word):\n",
    "    topic_words = np.array(vocab)[np.argsort(topic_dist)][:-(n_top_words+1):-1]\n",
    "    topic_summaries.append(' '.join(topic_words))\n",
    "\n",
    "topic_summaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
